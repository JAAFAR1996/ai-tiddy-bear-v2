src/infrastructure/logging_config.py
"""Centralized Logging Configuration.

This module configures application-wide logging with consistent standards and security.
It ensures sensitive data is not logged and appropriate verbosity is maintained.
"""

import hashlib  # Used only in log_child_interaction
import logging
import logging.handlers
import os
import re  # Used only in ChildSafetyFilter._redact
import sys
from datetime import UTC, datetime
from pathlib import Path
from typing import Any

from src.common.constants import (  # Import the new constant
    SENSITIVE_LOG_INTERACTION_KEYS,
)

LOGGING_LEVELS = {
    # Core application components
    "api": logging.INFO,
    "application": logging.INFO,
    "domain": logging.INFO,
    "infrastructure": logging.INFO,
    "presentation": logging.INFO,
    # Specific functional areas
    "security": logging.WARNING,  # Security events are always important
    "auth": logging.INFO,
    "child_safety": logging.WARNING,  # Child safety events are always important
    "database": logging.INFO,
    "cache": logging.INFO,
    "middleware": logging.INFO,
    "messaging": logging.INFO,
    "config": logging.INFO,
    "di": logging.INFO,  # Dependency Injection
    # Development/Debug components
    "debug": logging.DEBUG,
    "test": logging.DEBUG,
    # Default level for any unconfigured logger
    "default": logging.INFO,
}


def configure_logging(
    environment: str = "production",
    log_level: str | None = None,
    log_file: str | None = None,
) -> None:
    """Configures application-wide logging with consistent standards and security.
    Ensures sensitive data is not logged and appropriate verbosity is maintained.

    Args:
        environment (str): The current operating environment (e.g., "production", "development").
        log_level (Optional[str]): The desired base logging level (e.g., "INFO", "DEBUG").
        log_file (Optional[str]): Path to a file for logging output. If None, logs to console only.

    """
    # Determine base log level
    if log_level:
        base_level = getattr(logging, log_level.upper(), logging.INFO)
    else:
        base_level = logging.DEBUG if environment == "development" else logging.INFO

    # Configure root logger
    root_logger = logging.getLogger()
    root_logger.setLevel(base_level)

    # Clear existing handlers to prevent duplicate logs
    for handler in root_logger.handlers[:]:
        root_logger.removeHandler(handler)
        handler.close()

    # Use ProductionFormatter for all handlers
    formatter = ProductionFormatter(
        "%(asctime)s - %(levelname)s - %(name)s - %(message)s",
    )

    # Add ChildSafetyFilter to all handlers
src/domain/validators/safety_validator.py
src/infrastructure/validators/config/config_validators.py
src/infrastructure/validators/config/startup_validator.py
src/infrastructure/validators/data/comprehensive_validator.py
src/infrastructure/validators/data/database_validators.py
src/infrastructure/validators/data/emergency_contact_validator.py
src/infrastructure/validators/data/general_input_validator.py
src/infrastructure/validators/security/child_safety_validator.py
src/infrastructure/validators/security/coppa_validator.py
src/infrastructure/validators/security/database_input_validator.py
src/infrastructure/validators/security/email_validator.py
src/infrastructure/validators/security/environment_validator.py
src/infrastructure/validators/security/input_validator.py
src/infrastructure/validators/security/password_validator.py
src/infrastructure/validators/security/path_validator.py
src/infrastructure/validators/security/query_validator.py
src/infrastructure/validators/security/security_validator.py
src/presentation/validators/api_validators.py
src/infrastructure/config/services/content_moderation_settings.py
src/domain/interfaces/sanitization_service.py:    async def detect_pii(self, text: str) -> bool: ...
src/domain/safety/bias_detector/bias_detector.py:    async def detect_bias(
src/infrastructure/ai/chatgpt/response_enhancer.py:    def detect_emotion(self, response: str) -> str:
src/infrastructure/external_services/dummy_sanitization_service.py:    async def detect_pii(self, text: str) -> bool:
src/infrastructure/security/web/request_security_detector.py:    def detect_security_events(
src/infrastructure/validators/security/input_validator.py:        async def detect_sql_injection(self, text, field):
src/infrastructure/validators/security/input_validator.py:        async def detect_xss(self, text, field):
src/infrastructure/validators/security/input_validator.py:        async def detect_path_traversal(self, text, field):
src/infrastructure/validators/security/input_validator.py:        async def detect_command_injection(self, text, field):
src/infrastructure/validators/security/input_validator.py:        async def detect_ldap_injection(self, text, field):
src/infrastructure/validators/security/input_validator.py:        async def detect_template_injection(self, text, field):
src/infrastructure/validators/security/input_validator.py:        async def detect_inappropriate_content(self, text, field):
src/infrastructure/validators/security/input_validator.py:        async def detect_pii(self, text, field):
src/infrastructure/validators/security/input_validator.py:        async def detect_encoding_attacks(self, text, field):
src/presentation/api/decorators/rate_limit.py:def moderate_limit() -> Callable:
