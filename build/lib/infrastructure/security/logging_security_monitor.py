"""from pathlib import Pathfrom typing import Dict, List, Set, Any, Optionalimport loggingimport reimport warningsfrom .log_sanitizer import LogSanitizer, SensitiveDataType"""Logging Security MonitorThis module monitors and enforces secure logging practicesthroughout the AI Teddy Bear application to prevent data leaks."""class LoggingSecurityMonitor:    """    Ensures all log messages are sanitized and COPPA-compliant    before being written to log files.    """    def __init__(self) -> None:        self.sanitizer = LogSanitizer()        self.violations_found: List[Dict[str, Any]] = []        # Patterns to detect potential sensitive data in logs        self.sensitive_patterns = {            'email': r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b',            'phone': r'\b\+?[\d\s\-\(\)]{10,}\b',            'child_id': r'\bchild_id["\s]*[:=]["\s]*[A-Za-z0-9\-_]+',            'parent_id': r'\bparent_id["\s]*[:=]["\s]*[A-Za-z0-9\-_]+',            'ssn': r'\b\d{3}-?\d{2}-?\d{4}\b',            'credit_card': r'\b\d{4}[\s\-]?\d{4}[\s\-]?\d{4}[\s\-]?\d{4}\b',            'ip_address': r'\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b',            'api_key': r'\b[A-Za-z0-9]{32,}\b',            'password': r'password["\s]*[:=]["\s]*[^\s"\']+',            'token': r'token["\s]*[:=]["\s]*[A-Za-z0-9\-_\.]+',        }    def scan_codebase_for_violations(self, source_dir: str) -> Dict[str, Any]:        """        Scan the codebase for potential logging security violations        Args:            source_dir: Root directory to scan        Returns:            Report of findings and violations        """        violations = []        files_scanned = 0        source_path = Path(source_dir)        for py_file in source_path.rglob("*.py"):            files_scanned += 1            file_violations = self._scan_file_for_violations(py_file)            violations.extend(file_violations)        return {            "files_scanned": files_scanned,            "violations_found": len(violations),            "violations": violations,            "severity_counts": self._count_violations_by_severity(violations),            "recommendations": self._generate_recommendations(violations)        }    def _scan_file_for_violations(self, file_path: Path) -> List[Dict[str, Any]]:        """Scan a single file for logging violations"""        violations = []        try:            with open(file_path, 'r', encoding='utf-8') as f:                lines = f.readlines()            for line_num, line in enumerate(lines, 1):                # Check for logging statements                if self._is_logging_statement(line):                    # Check for sensitive data patterns                    for pattern_name, pattern in self.sensitive_patterns.items():                        matches = re.findall(pattern, line, re.IGNORECASE)                        if matches:                            violations.append({                                "file": str(file_path),                                "line": line_num,                                "line_content": line.strip(),                                "violation_type": pattern_name,                                "matches": matches,                                "severity": self._get_severity(pattern_name),                                "recommendation": self._get_recommendation(pattern_name)                            })        except Exception as e:            logging.warning(f"Failed to scan {file_path}: {e}")        return violations    def _is_logging_statement(self, line: str) -> bool:        """Check if line contains a logging statement"""        logging_patterns = [            r'logger\.(debug|info|warning|error|critical)',            r'logging\.(debug|info|warning|error|critical)',            r'print\s*\(',            r'console\.log',        ]        for pattern in logging_patterns:            if re.search(pattern, line, re.IGNORECASE):                return True        return False    def _get_severity(self, pattern_name: str) -> str:        """Get severity level for violation type"""        critical_patterns = {'child_id', 'parent_id', 'ssn', 'credit_card'}        high_patterns = {'email', 'phone', 'password', 'token', 'api_key'}        medium_patterns = {'ip_address', 'address'}        if pattern_name in critical_patterns:            return "CRITICAL"        elif pattern_name in high_patterns:            return "HIGH"        elif pattern_name in medium_patterns:            return "MEDIUM"        else:            return "LOW"    def _get_recommendation(self, pattern_name: str) -> str:        """Get recommendation for fixing violation"""        recommendations = {            'child_id': "Use sanitized_child_id = sanitizer.sanitize_child_id(child_id)",            'parent_id': "Use sanitized_parent_id = sanitizer.sanitize_parent_id(parent_id)",            'email': "Use masked_email = sanitizer.mask_email(email)",            'phone': "Use masked_phone = sanitizer.mask_phone(phone)",            'ssn': "Never log SSN - use sanitizer.hash_sensitive_data(ssn)",            'credit_card': "Never log credit card - use sanitizer.mask_payment_info()",            'password': "Never log passwords - remove from logging statement",            'token': "Never log tokens - use sanitizer.mask_token(token)",            'api_key': "Never log API keys - use sanitizer.mask_api_key(key)",            'ip_address': "Use sanitizer.anonymize_ip(ip_address) for GDPR compliance"        }        return recommendations.get(pattern_name, "Apply appropriate sanitization")    def _count_violations_by_severity(self, violations: List[Dict[str, Any]]) -> Dict[str, int]:        """Count violations by severity level"""        counts = {"CRITICAL": 0, "HIGH": 0, "MEDIUM": 0, "LOW": 0}        for violation in violations:            severity = violation.get("severity", "LOW")            counts[severity] += 1        return counts    def _generate_recommendations(self, violations: List[Dict[str, Any]]) -> List[str]:        """Generate actionable recommendations"""        recommendations = []        if violations:            recommendations.append(                "Integrate LogSanitizer into all logging statements that handle user data"            )            recommendations.append(                "Review and update logging practices to ensure COPPA compliance"            )            recommendations.append(                "Implement automated pre-commit hooks to catch logging violations"            )            recommendations.append(                "Train development team on secure logging practices for child safety"            )        else:            recommendations.append(                "âœ… No logging security violations found - good job!"            )        return recommendations    def create_secure_logging_wrapper(self) -> logging.Logger:        """        Create a logging wrapper that automatically sanitizes messages        Returns:            Logger instance with built-in sanitization        """        class SanitizedLogger:            def __init__(self, name: str, sanitizer: LogSanitizer) -> None:                self._logger = logging.getLogger(name)                self._sanitizer = sanitizer            def _sanitize_and_log(self, level: int, message: Any, *args, **kwargs):                """Sanitize message before logging"""                sanitized_message = self._sanitizer.sanitize_message(str(message))                self._logger.log(level, sanitized_message, *args, **kwargs)            def debug(self, message: Any, *args, **kwargs) -> None:                self._sanitize_and_log(logging.DEBUG, message, *args, **kwargs)            def info(self, message: Any, *args, **kwargs) -> None:                self._sanitize_and_log(logging.INFO, message, *args, **kwargs)            def warning(self, message: Any, *args, **kwargs) -> None:                self._sanitize_and_log(logging.WARNING, message, *args, **kwargs)            def error(self, message: Any, *args, **kwargs) -> None:                self._sanitize_and_log(logging.ERROR, message, *args, **kwargs)            def critical(self, message: Any, *args, **kwargs) -> None:                self._sanitize_and_log(logging.CRITICAL, message, *args, **kwargs)        return SanitizedLogger("secure_logger", self.sanitizer)    def setup_global_sanitization(self) -> None:        """Setup global logging sanitization for the entire application"""        # Create custom handler that sanitizes all log records        class SanitizingHandler(logging.Handler):            def __init__(self, sanitizer: LogSanitizer, original_handler: logging.Handler) -> None:                super().__init__()                self.sanitizer = sanitizer                self.original_handler = original_handler            def emit(self, record: logging.LogRecord) -> None:                # Sanitize the log message                if hasattr(record, 'msg') and record.msg:                    record.msg = self.sanitizer.sanitize_message(str(record.msg))                # Sanitize arguments                if hasattr(record, 'args') and record.args:                    sanitized_args = []                    for arg in record.args:                        sanitized_args.append(                            self.sanitizer.sanitize_message(str(arg))                        )                    record.args = tuple(sanitized_args)                # Forward to original handler                self.original_handler.emit(record)        # Get root logger        root_logger = logging.getLogger()        # Wrap existing handlers with sanitization        original_handlers = root_logger.handlers.copy()        root_logger.handlers.clear()        for handler in original_handlers:            sanitizing_handler = SanitizingHandler(self.sanitizer, handler)            root_logger.addHandler(sanitizing_handler)        logging.info("âœ… Global logging sanitization enabled")# Convenience functionsdef scan_for_logging_violations(source_dir: str = "src") -> Dict[str, Any]:    """Scan codebase for logging security violations"""    monitor = LoggingSecurityMonitor()    return monitor.scan_codebase_for_violations(source_dir)def create_secure_logger(name: str) -> logging.Logger:    """Create a logger with automatic sanitization"""    monitor = LoggingSecurityMonitor()    return monitor.create_secure_logging_wrapper()def enable_global_sanitization() -> None:    """Enable sanitization for all loggers in the application"""    monitor = LoggingSecurityMonitor()    monitor.setup_global_sanitization()if __name__ == "__main__":    # Run a security scan when executed directly - PRODUCTION SAFE: Using proper logging    import logging    logging.basicConfig(level=logging.INFO)    from src.infrastructure.logging_config import get_loggerlogger = get_logger(__name__, component="security")    logger.info("ðŸ” Scanning for logging security violations...")    results = scan_for_logging_violations()    logger.info(f"\nðŸ“Š Scan Results:")    logger.info(f"Files scanned: {results['files_scanned']}")    logger.info(f"Violations found: {results['violations_found']}")    if results['violations_found'] > 0:        logger.warning(f"\nâš ï¸ Severity breakdown:")        for severity, count in results['severity_counts'].items():            if count > 0:                logger.warning(f"  {severity}: {count}")        logger.info(f"\nðŸ’¡ Recommendations:")        for rec in results['recommendations']:            logger.info(f"  â€¢ {rec}")    else:        logger.info("âœ… No logging security violations found!")