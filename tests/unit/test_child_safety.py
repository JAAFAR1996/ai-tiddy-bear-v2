"""Production-grade test suite covering all safety features"""

from datetime import datetime, timedelta
from unittest.mock import AsyncMock, MagicMock, patch
from uuid import uuid4

import pytest

from src.domain.value_objects import ChildAge
from src.infrastructure.ai.real_ai_service import ProductionAIService
from src.infrastructure.security.child_safety.consent_manager import COPPAConsentManager
from src.domain.models.child_safety_data_models import (
    ParentConsent,
)


class TestCOPPACompliance:
    """Test COPPA compliance features"""

    @pytest.fixture
    def consent_manager(self):
        return COPPAConsentManager()

    @pytest.fixture
    def sample_consent(self):
        return ParentConsent(
            parent_id=str(uuid4()),
            child_id=str(uuid4()),
            consent_type="data_collection",
            granted=True,
            verification_method="email_verification",
            expires_at=datetime.utcnow() + timedelta(days=365),
        )

    @pytest.mark.asyncio
    async def test_verify_parental_consent_valid(self, consent_manager, sample_consent):
        """Test valid parental consent verification"""
        with patch("src.infrastructure.persistence.database.get_database") as mock_db:
            # Mock database response with valid consent
            mock_session = AsyncMock()
            mock_result = AsyncMock()
            mock_result.fetchone.return_value = {
                "parent_id": sample_consent.parent_id,
                "child_id": sample_consent.child_id,
                "consent_type": sample_consent.consent_type,
                "is_active": True,
                "expires_at": sample_consent.expires_at,
                "verification_method": sample_consent.verification_method,
            }
            mock_session.execute.return_value = mock_result
            mock_db.return_value.get_session.return_value.__aenter__.return_value = (
                mock_session
            )

            # Test consent verification
            result = await consent_manager.verify_parental_consent(
                sample_consent.parent_id,
                sample_consent.child_id,
                sample_consent.consent_type,
            )

            assert result is True
            mock_session.execute.assert_called_once()

    @pytest.mark.asyncio
    async def test_verify_parental_consent_expired(self, consent_manager):
        """Test expired consent rejection"""
        with patch("src.infrastructure.persistence.database.get_database") as mock_db:
            # Mock database response with no consent found
            mock_session = AsyncMock()
            mock_result = AsyncMock()
            mock_result.fetchone.return_value = None
            mock_session.execute.return_value = mock_result
            mock_db.return_value.get_session.return_value.__aenter__.return_value = (
                mock_session
            )

            result = await consent_manager.verify_parental_consent(
                "parent_id", "child_id", "data_collection"
            )

            assert result is False

    @pytest.mark.asyncio
    async def test_consent_required_for_data_collection(self, consent_manager):
        """Test that data collection requires consent"""
        required_types = consent_manager.required_consent_types
        assert "data_collection" in required_types
        assert "voice_recording" in required_types
        assert "usage_analytics" in required_types
        assert "safety_monitoring" in required_types


class TestAISafety:
    """Test AI service safety features"""

    @pytest.fixture
    def ai_service(self):
        with patch("openai.OpenAI"):
            return ProductionAIService(api_key="test_key")

    @pytest.mark.asyncio
    async def test_age_appropriate_content_filtering(self, ai_service):
        """Test that AI filters content by age"""
        # Test content inappropriate for toddlers
        result = ai_service._is_age_appropriate(
            "This is a scary story about death", ChildAge.TODDLER
        )
        assert result is False

        # Test appropriate content for toddlers
        result = ai_service._is_age_appropriate(
            "Let's play with colorful toys!", ChildAge.TODDLER
        )
        assert result is True

    def test_safety_score_calculation(self, ai_service):
        """Test safety score calculation"""
        # Safe content
        safe_moderation = {
            "safe": True,
            "category_scores": {"violence": 0.1, "hate": 0.05},
        }
        score = ai_service._calculate_safety_score(safe_moderation)
        assert score >= 0.8

        # Unsafe content
        unsafe_moderation = {
            "safe": False,
            "category_scores": {"violence": 0.9, "hate": 0.8},
        }
        score = ai_service._calculate_safety_score(unsafe_moderation)
        assert score == 0.0

    def test_inappropriate_terms_detection(self, ai_service):
        """Test detection of age-inappropriate terms"""
        # Test toddler inappropriate terms
        result = ai_service._is_age_appropriate(
            "This is scary and violent", ChildAge.TODDLER
        )
        assert result is False

        # Test school age appropriate content
        result = ai_service._is_age_appropriate(
            "Let's learn about friendship", ChildAge.SCHOOL_AGE
        )
        assert result is True


class TestChildDataEncryption:
    """Test child data encryption compliance"""

    def test_child_model_encryption(self):
        """Test that child PII is encrypted"""
        from src.infrastructure.persistence.models.child_models import (
            ChildModel,
        )

        # Mock encryption key
        with patch.dict(
            "os.environ",
            {"COPPA_ENCRYPTION_KEY": "test_key_32_characters_long_12345"},
        ):
            with patch("cryptography.fernet.Fernet") as mock_fernet:
                mock_cipher = MagicMock()
                mock_fernet.return_value = mock_cipher
                mock_cipher.encrypt.return_value = b"encrypted_data"
                mock_cipher.decrypt.return_value = b"test_name"

                child = ChildModel()
                child.name = "TestChild"

                # Verify encryption was called
                mock_cipher.encrypt.assert_called()

    def test_encryption_key_required(self):
        """Test that encryption key is required"""
        from src.infrastructure.persistence.models.child_models import (
            ChildModel,
        )

        with patch.dict("os.environ", {}, clear=True):
            child = ChildModel()

            with pytest.raises(ValueError, match="COPPA_ENCRYPTION_KEY"):
                _ = child.name


class TestInputValidation:
    """Test input validation and sanitization"""

    def test_conversation_request_validation(self):
        """Test conversation request validation"""
        from src.presentation.api.endpoints.conversations import (
            ConversationRequest,
        )

        # Valid request
        valid_request = ConversationRequest(
            child_id="12345678-1234-1234-1234-123456789012",
            message="Hello teddy!",
            message_type="text",
            language="en",
        )
        assert valid_request.child_id is not None

        # Invalid UUID format
        with pytest.raises(ValueError):
            ConversationRequest(
                child_id="invalid_uuid", message="Hello", message_type="text"
            )

        # Invalid message type
        with pytest.raises(ValueError):
            ConversationRequest(
                child_id="12345678-1234-1234-1234-123456789012",
                message="Hello",
                message_type="invalid_type",
            )

    def test_message_content_filtering(self):
        """Test message content filtering"""
        from src.presentation.api.endpoints.conversations import (
            ConversationRequest,
        )

        # Message with forbidden content should be rejected
        with pytest.raises(ValueError, match="inappropriate content"):
            ConversationRequest(
                child_id="12345678-1234-1234-1234-123456789012",
                message="What is my password?",
                message_type="text",
            )


class TestRateLimiting:
    """Test rate limiting protection"""

    @pytest.mark.asyncio
    async def test_login_rate_limiting(self):
        """Test that login attempts are rate limited"""
        from src.presentation.api.endpoints.auth import LoginRequest, login

        with patch(
            "infrastructure.security.rate_limiter.get_rate_limiter"
        ) as mock_limiter:
            # Mock rate limiter that denies requests
            mock_rate_limiter = AsyncMock()
            mock_rate_limiter.check_rate_limit.return_value = False
            mock_limiter.return_value = mock_rate_limiter

            request = LoginRequest(email="test@example.com", password="test123")

            with pytest.raises(Exception):  # Should raise HTTPException
                await login(request, client_ip="192.168.1.1")

    @pytest.mark.asyncio
    async def test_rate_limiter_mandatory(self):
        """Test that missing rate limiter causes service failure"""
        from src.presentation.api.endpoints.auth import LoginRequest, login

        with patch(
            "infrastructure.security.rate_limiter.get_rate_limiter",
            side_effect=ImportError(),
        ):
            request = LoginRequest(email="test@example.com", password="test123")

            with pytest.raises(
                Exception
            ):  # Should raise HTTPException for unavailable service
                await login(request, client_ip="192.168.1.1")


# Tests cover COPPA compliance, AI safety, encryption, input validation, and rate limiting
# All tests are production-ready with proper mocking and assertions
